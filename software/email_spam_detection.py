# -*- coding: utf-8 -*-
"""Email Spam Detection

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hKHGNXJ9EwrOwG3olers15KdJquC8nyq
"""

# Import Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Embedding, LSTM, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dropout
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.metrics import classification_report, confusion_matrix
from wordcloud import WordCloud

# Load dataset
data = pd.read_csv('/content/email_spam.csv')

data.head()

data.info()

data.describe()

print(data.columns)

print(data['type'].unique())

# Visualization of the distribution of spam and not spam emails
plt.figure(figsize=(8, 5))
data['type'].value_counts().plot(kind='bar', color=['skyblue', 'salmon'])
plt.title('Distribution of Spam and Not Spam Emails')
plt.xlabel('Email Type')
plt.xticks(ticks=[0, 1], labels=['Not Spam (0)', 'Spam (1)'], rotation=0)
plt.ylabel('Count')
plt.show()

# Filter spam emails (1 for spam)
spam_emails = data[data['type'] == 1]['text']
print(f'Number of spam emails: {len(spam_emails)}')

if len(spam_emails) > 0:
    spam_text = ' '.join(spam_emails)

    # Create a word cloud
    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(spam_text)

    plt.figure(figsize=(10, 5))
    plt.imshow(wordcloud, interpolation='bilinear')
    plt.axis('off')
    plt.title('Word Cloud for Spam Emails')
    plt.show()
else:
    print("No spam emails found.")

# Filter not spam emails (0 for not spam)
not_spam_emails = data[data['type'] == 0]['text']
print(f'Number of not spam emails: {len(not_spam_emails)}')

# Create a word cloud for not spam emails
if len(not_spam_emails) > 0:
    not_spam_text = ' '.join(not_spam_emails)

    # Generate the word cloud
    wordcloud_not_spam = WordCloud(width=800, height=400, background_color='white').generate(not_spam_text)

    plt.figure(figsize=(10, 5))
    plt.imshow(wordcloud_not_spam, interpolation='bilinear')
    plt.axis('off')
    plt.title('Word Cloud for Not Spam Emails')
    plt.show()
else:
    print("No not spam emails found.")

# Encode labels
label_encoder = LabelEncoder()
data['type'] = label_encoder.fit_transform(data['type'])  # Spam = 1, Not Spam = 0

# Split dataset
X_train, X_test, y_train, y_test = train_test_split(data['text'], data['type'], test_size=0.2, random_state=42)

# Tokenization
tokenizer = Tokenizer(num_words=5000)
tokenizer.fit_on_texts(X_train)

X_train_seq = tokenizer.texts_to_sequences(X_train)
X_test_seq = tokenizer.texts_to_sequences(X_test)

# Padding sequences
max_length = 100
X_train_pad = pad_sequences(X_train_seq, maxlen=max_length)
X_test_pad = pad_sequences(X_test_seq, maxlen=max_length)

# Model definition
model = Sequential()
model.add(Embedding(input_dim=5000, output_dim=128, input_length=max_length))
model.add(Conv1D(filters=64, kernel_size=5, activation='relu'))
model.add(MaxPooling1D(pool_size=2))
model.add(LSTM(64, return_sequences=True))
model.add(GlobalMaxPooling1D())
model.add(Dropout(0.5))
model.add(Dense(1, activation='sigmoid'))  # Binary classification

model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

model.summary()

# Early stopping
early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

# Train the model
history = model.fit(X_train_pad, y_train, epochs=10, batch_size=32,
                    validation_split=0.1, callbacks=[early_stopping])

# Model evaluation
y_pred = model.predict(X_test_pad)
y_pred_classes = (y_pred > 0.5).astype(int)

print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred_classes))

print("\nClassification Report:")
print(classification_report(y_test, y_pred_classes))

# Save the model
model.save('email_spam_detector.h5')

# To load the model later
from tensorflow.keras.models import load_model
loaded_model = load_model('email_spam_detector.h5')

# Plot training & validation loss values
plt.figure(figsize=(12, 6))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(loc='upper right')
plt.show()

# Plot training & validation accuracy values
plt.figure(figsize=(12, 6))
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(loc='upper left')
plt.show()

import seaborn as sns
from sklearn.metrics import confusion_matrix

cm = confusion_matrix(y_test, y_pred_classes)

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Not Spam', 'Spam'],
            yticklabels=['Not Spam', 'Spam'])
plt.title('Confusion Matrix')
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.show()

from sklearn.metrics import classification_report
import pandas as pd

report = classification_report(y_test, y_pred_classes, output_dict=True)
report_df = pd.DataFrame(report).transpose()

plt.figure(figsize=(10, 6))
sns.heatmap(report_df.iloc[:-1, :].T, annot=True, cmap='Blues')
plt.title('Classification Report')
plt.show()

from sklearn.metrics import roc_curve, auc

fpr, tpr, _ = roc_curve(y_test, y_pred)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(10, 6))
plt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic')
plt.legend(loc="lower right")
plt.show()



